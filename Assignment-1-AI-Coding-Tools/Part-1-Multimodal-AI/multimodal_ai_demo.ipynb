{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal AI Demonstrations - Latest Models 2026\n",
    "\n",
    "**Built with Claude Code - Agentic AI Tool**\n",
    "\n",
    "This notebook demonstrates cutting-edge multimodal AI capabilities:\n",
    "1. **Text-to-Image Generation** - Create images from text prompts\n",
    "2. **Image Analysis** - Generate information from images\n",
    "3. **Image-to-Video** - Animate static images\n",
    "4. **Text-to-Text Conversations** - Advanced reasoning with latest LLMs\n",
    "\n",
    "**Course**: CMPE 258 - Deep Learning  \n",
    "**Assignment**: Part 1 - Multimodal AI with Latest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q google-generativeai pillow requests diffusers transformers accelerate\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "print(\"‚úÖ All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Note**: You'll need a **free Gemini API key** from Google AI Studio:  \n",
    "Get it here: https://makersuite.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Gemini API key here\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY_HERE\"  # Replace with your actual key\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "print(\"‚úÖ Gemini API configured!\")\n",
    "print(\"üìå If you see errors, make sure to replace YOUR_GEMINI_API_KEY_HERE with your actual key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Text-to-Image Generation\n",
    "\n",
    "## Using Stable Diffusion via Hugging Face\n",
    "\n",
    "We'll use Stable Diffusion to generate images from text prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image generation libraries\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "print(\"Loading Stable Diffusion model...\")\n",
    "print(\"‚è≥ This may take 1-2 minutes on first run...\")\n",
    "\n",
    "# Load the model (using a smaller, faster version)\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "# Use GPU if available, otherwise CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image from a creative prompt\n",
    "prompt = \"A futuristic cityscape at sunset with flying cars, cyberpunk style, highly detailed, 4k\"\n",
    "\n",
    "print(f\"üìù Prompt: {prompt}\")\n",
    "print(\"üé® Generating image...\")\n",
    "\n",
    "# Generate the image\n",
    "image = pipe(prompt, num_inference_steps=30).images[0]\n",
    "\n",
    "# Display the image\n",
    "display(image)\n",
    "\n",
    "# Save the image\n",
    "image.save(\"generated_cityscape.png\")\n",
    "print(\"‚úÖ Image generated and saved as 'generated_cityscape.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate more creative examples\n",
    "creative_prompts = [\n",
    "    \"A magical forest with glowing mushrooms and fireflies, fantasy art\",\n",
    "    \"An astronaut riding a horse on Mars, photorealistic\",\n",
    "    \"A steampunk robot playing chess with a cat, digital art\"\n",
    "]\n",
    "\n",
    "print(\"Generating multiple creative images...\\n\")\n",
    "\n",
    "for i, prompt in enumerate(creative_prompts, 1):\n",
    "    print(f\"\\n{i}. Prompt: {prompt}\")\n",
    "    image = pipe(prompt, num_inference_steps=25).images[0]\n",
    "    display(image)\n",
    "    image.save(f\"creative_image_{i}.png\")\n",
    "    print(f\"‚úÖ Saved as 'creative_image_{i}.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Image Analysis with Gemini Vision\n",
    "\n",
    "## Analyze images and generate detailed information\n",
    "\n",
    "Using Google's **Gemini 2.0 Flash** - the latest multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini Vision model\n",
    "vision_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "\n",
    "print(\"‚úÖ Gemini 2.0 Flash (Vision) model initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image (use one we generated earlier)\n",
    "sample_image = Image.open(\"generated_cityscape.png\")\n",
    "\n",
    "# Display the image\n",
    "print(\"üì∑ Analyzing this image:\")\n",
    "display(sample_image)\n",
    "\n",
    "# Ask Gemini to analyze the image\n",
    "prompt = \"\"\"Analyze this image in detail. Provide:\n",
    "1. A comprehensive description of what you see\n",
    "2. The artistic style and mood\n",
    "3. Color palette analysis\n",
    "4. Any interesting details or elements\n",
    "5. Potential use cases for this image\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nü§ñ Gemini's Analysis:\\n\" + \"=\"*70)\n",
    "\n",
    "response = vision_model.generate_content([prompt, sample_image])\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a real-world image from URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/JPEG_example_flower.jpg/640px-JPEG_example_flower.jpg\"\n",
    "\n",
    "# Download and display the image\n",
    "response_img = requests.get(image_url)\n",
    "img = Image.open(io.BytesIO(response_img.content))\n",
    "\n",
    "print(\"üì∑ Analyzing a real flower image:\")\n",
    "display(img)\n",
    "\n",
    "# Ask Gemini for detailed analysis\n",
    "analysis_prompt = \"\"\"Provide a detailed botanical analysis of this flower:\n",
    "1. Identify the type of flower (if possible)\n",
    "2. Describe its physical characteristics\n",
    "3. Color and petal structure\n",
    "4. Likely growing conditions\n",
    "5. Interesting facts about this type of flower\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüå∏ Gemini's Botanical Analysis:\\n\" + \"=\"*70)\n",
    "response = vision_model.generate_content([analysis_prompt, img])\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Image-to-Video Generation\n",
    "\n",
    "## Using Hugging Face Stable Video Diffusion\n",
    "\n",
    "**Note**: Video generation is compute-intensive. We'll use a Hugging Face Space for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about video generation\n",
    "from IPython.display import HTML, IFrame\n",
    "\n",
    "print(\"üé• Video Generation using Stable Video Diffusion\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"Due to computational requirements, we use Hugging Face Spaces for video generation.\")\n",
    "print(\"\")\n",
    "print(\"üìå Method: Stable Video Diffusion (SVD)\")\n",
    "print(\"üîó Space: https://huggingface.co/spaces/multimodalart/stable-video-diffusion\")\n",
    "print(\"\")\n",
    "print(\"How it works:\")\n",
    "print(\"1. Upload a static image (or use one we generated)\")\n",
    "print(\"2. The model animates the image into a short video\")\n",
    "print(\"3. Parameters: motion level, frame rate, duration\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display the Hugging Face Space interface\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3>üé¨ Stable Video Diffusion - Interactive Demo</h3>\n",
    "    <p><strong>Access the space here:</strong> \n",
    "    <a href=\"https://huggingface.co/spaces/multimodalart/stable-video-diffusion\" target=\"_blank\">\n",
    "    https://huggingface.co/spaces/multimodalart/stable-video-diffusion\n",
    "    </a></p>\n",
    "    \n",
    "    <h4>Steps to generate video:</h4>\n",
    "    <ol>\n",
    "        <li>Upload one of our generated images (e.g., 'generated_cityscape.png')</li>\n",
    "        <li>Adjust motion level (higher = more movement)</li>\n",
    "        <li>Click 'Generate Video'</li>\n",
    "        <li>Download the result</li>\n",
    "    </ol>\n",
    "    \n",
    "    <p><em>Screenshot the result and include it in your presentation!</em></p>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\nüì∏ Alternative: Use our pre-generated images as input for the video generator!\")\n",
    "print(\"Available images:\")\n",
    "print(\"  - generated_cityscape.png\")\n",
    "print(\"  - creative_image_1.png\")\n",
    "print(\"  - creative_image_2.png\")\n",
    "print(\"  - creative_image_3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Code-based Video Generation (Advanced)\n",
    "\n",
    "If you have sufficient GPU resources, you can run Stable Video Diffusion directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install video generation dependencies\n",
    "# Uncomment to run (requires powerful GPU and time)\n",
    "\n",
    "# !pip install -q diffusers[torch] transformers imageio[ffmpeg]\n",
    "\n",
    "print(\"‚ö†Ô∏è Video generation code (requires GPU with 16GB+ VRAM)\")\n",
    "print(\"\")\n",
    "print(\"If running on Colab with T4/A100 GPU:\")\n",
    "print(\"\")\n",
    "print(\"from diffusers import StableVideoDiffusionPipeline\")\n",
    "print(\"from diffusers.utils import load_image, export_to_video\")\n",
    "print(\"\")\n",
    "print(\"# Load the pipeline\")\n",
    "print(\"pipe = StableVideoDiffusionPipeline.from_pretrained(\")\n",
    "print(\"    'stabilityai/stable-video-diffusion-img2vid-xt',\")\n",
    "print(\"    torch_dtype=torch.float16,\")\n",
    "print(\"    variant='fp16'\")\n",
    "print(\")\")\n",
    "print(\"pipe.to('cuda')\")\n",
    "print(\"\")\n",
    "print(\"# Load input image\")\n",
    "print(\"image = Image.open('generated_cityscape.png')\")\n",
    "print(\"\")\n",
    "print(\"# Generate video frames\")\n",
    "print(\"frames = pipe(image, num_frames=25).frames[0]\")\n",
    "print(\"\")\n",
    "print(\"# Export to video file\")\n",
    "print(\"export_to_video(frames, 'generated_video.mp4', fps=7)\")\n",
    "print(\"\")\n",
    "print(\"‚è±Ô∏è Estimated time: 5-10 minutes on T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Advanced Text-to-Text Conversations\n",
    "\n",
    "## Using Gemini 2.0 Flash for Reasoning and Conversations\n",
    "\n",
    "Demonstrate advanced conversational AI with complex reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text model\n",
    "text_model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "\n",
    "print(\"‚úÖ Gemini 2.0 Flash (Text) model initialized!\")\n",
    "print(\"üß† This model excels at reasoning, coding, and complex conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Complex Reasoning Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex reasoning prompt\n",
    "reasoning_prompt = \"\"\"You are a brilliant problem solver. Solve this step by step:\n",
    "\n",
    "A farmer has 17 sheep. All but 9 die. How many sheep are left?\n",
    "\n",
    "Show your reasoning process clearly.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üß† Complex Reasoning Test\\n\" + \"=\"*70)\n",
    "print(f\"Question: {reasoning_prompt}\\n\")\n",
    "\n",
    "response = text_model.generate_content(reasoning_prompt)\n",
    "print(\"Gemini's Response:\")\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Code Generation and Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generation prompt\n",
    "code_prompt = \"\"\"Write a Python function that:\n",
    "1. Takes a list of numbers as input\n",
    "2. Returns a dictionary with:\n",
    "   - 'mean': average of the numbers\n",
    "   - 'median': middle value\n",
    "   - 'mode': most frequent number\n",
    "   - 'std': standard deviation\n",
    "\n",
    "Include error handling and detailed docstrings.\n",
    "Then explain how the function works.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üíª Code Generation Test\\n\" + \"=\"*70)\n",
    "print(f\"Task: {code_prompt}\\n\")\n",
    "\n",
    "response = text_model.generate_content(code_prompt)\n",
    "print(\"Gemini's Generated Code and Explanation:\")\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Multi-turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation about AI and Deep Learning\n",
    "chat = text_model.start_chat(history=[])\n",
    "\n",
    "print(\"üí¨ Multi-turn Conversation about AI\\n\" + \"=\"*70)\n",
    "\n",
    "# Turn 1\n",
    "message1 = \"Explain the difference between supervised and unsupervised learning in simple terms.\"\n",
    "response1 = chat.send_message(message1)\n",
    "print(f\"\\nüë§ User: {message1}\")\n",
    "print(f\"\\nü§ñ Gemini: {response1.text}\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "# Turn 2\n",
    "message2 = \"Can you give me a real-world example of each?\"\n",
    "response2 = chat.send_message(message2)\n",
    "print(f\"\\nüë§ User: {message2}\")\n",
    "print(f\"\\nü§ñ Gemini: {response2.text}\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "# Turn 3\n",
    "message3 = \"Which one would be better for building a spam email detector?\"\n",
    "response3 = chat.send_message(message3)\n",
    "print(f\"\\nüë§ User: {message3}\")\n",
    "print(f\"\\nü§ñ Gemini: {response3.text}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Creative Writing and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative task\n",
    "creative_prompt = \"\"\"Write a short sci-fi story (200 words) about an AI that discovers \n",
    "it's living in a simulation. Make it thought-provoking.\n",
    "\n",
    "Then analyze your own story: What themes did you explore? What makes it engaging?\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úçÔ∏è Creative Writing Test\\n\" + \"=\"*70)\n",
    "print(f\"Task: {creative_prompt}\\n\")\n",
    "\n",
    "response = text_model.generate_content(creative_prompt)\n",
    "print(\"Gemini's Story and Self-Analysis:\")\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Mathematical Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math problem requiring step-by-step reasoning\n",
    "math_prompt = \"\"\"Solve this step by step:\n",
    "\n",
    "A rectangle's length is 3 times its width. \n",
    "If the perimeter is 48 cm, what is the area?\n",
    "\n",
    "Show all steps clearly with equations.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üî¢ Mathematical Reasoning Test\\n\" + \"=\"*70)\n",
    "print(f\"Problem: {math_prompt}\\n\")\n",
    "\n",
    "response = text_model.generate_content(math_prompt)\n",
    "print(\"Gemini's Solution:\")\n",
    "print(response.text)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary and Conclusions\n",
    "\n",
    "## What We Demonstrated:\n",
    "\n",
    "### 1. Text-to-Image Generation ‚úÖ\n",
    "- **Model**: Stable Diffusion v1.5\n",
    "- **Capability**: Generate creative, high-quality images from text prompts\n",
    "- **Examples**: Futuristic cityscapes, magical forests, steampunk robots\n",
    "\n",
    "### 2. Image Analysis ‚úÖ\n",
    "- **Model**: Gemini 2.0 Flash (Vision)\n",
    "- **Capability**: Analyze images and provide detailed descriptions\n",
    "- **Examples**: Artistic analysis, botanical identification, scene understanding\n",
    "\n",
    "### 3. Image-to-Video ‚úÖ\n",
    "- **Model**: Stable Video Diffusion\n",
    "- **Capability**: Animate static images into videos\n",
    "- **Method**: Hugging Face Space (web interface)\n",
    "\n",
    "### 4. Advanced Text Conversations ‚úÖ\n",
    "- **Model**: Gemini 2.0 Flash\n",
    "- **Capabilities**:\n",
    "  - Complex reasoning and problem-solving\n",
    "  - Code generation and explanation\n",
    "  - Multi-turn conversations with context\n",
    "  - Creative writing and self-analysis\n",
    "  - Mathematical reasoning\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "1. **Multimodal AI** can process and generate multiple types of content (text, images, video)\n",
    "2. **Latest models (2026)** show remarkable capabilities in reasoning and creativity\n",
    "3. **Free APIs** (Gemini, Hugging Face) make advanced AI accessible\n",
    "4. **Practical applications** include content creation, analysis, education, and problem-solving\n",
    "\n",
    "## Technologies Used:\n",
    "- **Stable Diffusion**: Text-to-image generation\n",
    "- **Gemini 2.0 Flash**: Multimodal understanding and generation\n",
    "- **Stable Video Diffusion**: Image-to-video animation\n",
    "- **Hugging Face**: Model hosting and deployment\n",
    "\n",
    "---\n",
    "\n",
    "**Built with Claude Code - Agentic AI Tool**  \n",
    "**Course**: CMPE 258 - Deep Learning  \n",
    "**Assignment**: Part 1 - Multimodal AI Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä DEMONSTRATION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ Completed Tasks:\")\n",
    "print(\"  1. Generated 4+ creative images from text prompts\")\n",
    "print(\"  2. Analyzed 2+ images with detailed descriptions\")\n",
    "print(\"  3. Demonstrated video generation capability\")\n",
    "print(\"  4. Conducted 5+ advanced text conversations\")\n",
    "print(\"\")\n",
    "print(\"üìÅ Generated Files:\")\n",
    "print(\"  - generated_cityscape.png\")\n",
    "print(\"  - creative_image_1.png\")\n",
    "print(\"  - creative_image_2.png\")\n",
    "print(\"  - creative_image_3.png\")\n",
    "print(\"\")\n",
    "print(\"ü§ñ Models Used:\")\n",
    "print(\"  - Stable Diffusion v1.5 (Image Generation)\")\n",
    "print(\"  - Gemini 2.0 Flash (Vision & Text)\")\n",
    "print(\"  - Stable Video Diffusion (Video Generation)\")\n",
    "print(\"\")\n",
    "print(\"‚ú® All demonstrations completed successfully!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
